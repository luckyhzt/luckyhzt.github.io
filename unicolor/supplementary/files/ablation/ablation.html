<!DOCTYPE html>
<html>
<head>
<style>
    
body, html{
    margin: 0;
    padding: 0;
    height: 100%;
    overflow: auto;
}

.my_text{
    font-size: 22px;
}

#inner {
  left: 24%; 
  top: 45px; 
  width: 52%; 
  height: auto; 
  position: absolute; 
  z-index: 1;
}

.my_table {
  font-family: arial, sans-serif;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  width: 70%;
}

td, th {
  border: 1.5px solid #706f6f;
  text-align: left;
  padding: 10px;
}

</style>
</head>

<body>

<div class="my_text" id="inner">
    We perform an additional ablation study on color space by training another variant with LAB color space. 
    More specifically, we input L-channel of the image to the gray encoder of Chroma-VQGAN, and input ab-channel of the image to the color encoder.
    Then we train the Hybrid-Transformer to predict the color tokens representing features of ab-channel given the unquantized features of L-channel.
    The colorized image is generated by combining the predicted ab-channel and the input L-channel.
    We first show the quantitative comparison on unconditional colorization with 5,000 images from Imagenet.
    As shown in the table below, using LAB color space has a comparable performance. 
    <strong>This indicates that our model is robust and can be directly applied to other color spaces without further modifications.</strong>
    We also show some qualitative comparisons in the figure below.
    <p> </p>
    <table class="my_table">
      <tr>
        <th> </th>
        <th>FID&darr;</th>
        <th>Colorfulness&uarr;</th>
      </tr>
      <tr>
        <td>LAB</td>
        <td>10.12</td>
        <td>38.49</td>
      </tr>
      <tr>
        <td>Ours</td>
        <td><strong>9.46</strong></td>
        <td><strong>39.01</strong></td>
      </tr>
    </table>
    <p></p>
    <p></p>
    <iframe src="compare/index.html" name="comp" frameborder="0" style="position: absolute; height: 160%; width: 100%;"></iframe>
</div>

</body>
</html>